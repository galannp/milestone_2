{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7eaaa1fc-6a2e-4739-ae3e-be90ffe237c9",
   "metadata": {},
   "source": [
    "# Project Milestone2 - Group Concatsanddogs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690106c9-c202-4b13-a41c-335544c35ecd",
   "metadata": {},
   "source": [
    "# The use of women's rights and gender equality rhetoric in the US"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6858764-e568-45ca-a871-5c5fa855b5b5",
   "metadata": {},
   "source": [
    "## Header"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8987c2ee-6b5d-496c-9450-163f1ab569a1",
   "metadata": {},
   "source": [
    "This notebook is organized followings the different steps used in our pipeline. We first create a list of keywords using [web scraping](#Webscraping) and a personal list of keywords. \n",
    "With this list of keywords we [select](#Dataset-selection-from-Quotebank-database) a subset of the Quotebank database. This subset will be our starting dataset for our project. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569a8fe1-2f1f-45ed-b256-75a7ddd90a72",
   "metadata": {},
   "source": [
    "## General librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef090096-3676-405b-a169-7efe712c5b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f294bf29-de89-4787-805b-0f98233329f1",
   "metadata": {},
   "source": [
    "## Webscraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef16436-c959-41b4-a35b-aacc530377ab",
   "metadata": {},
   "source": [
    "AMINA TO ADD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20430e1b-9f9c-445d-9e25-7b447c2395df",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393d0fde-ee26-4582-abc4-445db2682a22",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d551a663-d2c4-4844-94db-6a8f4c2a3ed6",
   "metadata": {},
   "source": [
    "## Dataset selection from Quotebank database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea3d42c-938d-4915-b6f5-4426b078eed0",
   "metadata": {},
   "source": [
    "### Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7f9b793-f2e2-481f-8080-068996db859b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1d7808-e93a-4d3f-b9c1-42ca2756c8a8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "161934f4-7a89-4a52-a21d-9c2b9dc186ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Processing on chunk\n",
    "#Input\n",
    "#Output\n",
    "def process_chunk(chunk, vocabulary):\n",
    "    print(f'Processing chunk with {len(chunk)} rows')\n",
    "    #print(chunk.columns)\n",
    "    occurences = np.zeros(len(vocabulary))\n",
    "    for index, word in enumerate(vocabulary):\n",
    "        occurences[index] = np.sum(chunk['quotation'].str.contains(word)) \n",
    "    return occurences\n",
    "\n",
    "#Select quotes containing keywords\n",
    "def select_quotes_chunk(chunk, keywords):\n",
    "    print(f'Processing chunk with {len(chunk)} rows')\n",
    "    return chunk[chunk['quotation'].str.contains('|'.join(keywords))]\n",
    "\n",
    "#Use the selection function on each chunk of the full dataset \n",
    "def select_quotes_one_year(path_to_file, vocabulary, chunksize = 10 ** 4):\n",
    "    with pd.read_json(path_to_file, lines=True, compression='bz2', chunksize=chunksize) as df_reader:\n",
    "        for index, chunk in enumerate(df_reader):\n",
    "            if not index==0:\n",
    "                selected_df = pd.concat([selected_df, select_quotes_chunk(chunk, vocabulary)])\n",
    "            else: \n",
    "                selected_df = select_quotes_chunk(chunk, vocabulary)\n",
    "    return selected_df\n",
    "\n",
    "#Use the selection function on each chunk of the full dataset \n",
    "#Dumps the selected quotes into a new json file\n",
    "def select_and_dump(path_to_file, vocabulary, chunksize = 10 ** 4, year = 'replace_me'):\n",
    "    with pd.read_json(path_to_file, lines=True, compression='bz2', chunksize=chunksize) as df_reader:\n",
    "        for index, chunk in enumerate(df_reader):\n",
    "            #Dump selected quotes\n",
    "            selected_df = select_quotes_chunk(chunk, vocabulary)\n",
    "            pickle_file_name = year + '_chunk_' + str(index) + '.pkl'\n",
    "            selected_df.to_pickle('files/'+pickle_file_name)\n",
    "            #if not index==0:\n",
    "                #selected_df = pd.concat([selected_df, select_quotes_chunk(chunk, vocabulary)])\n",
    "            #else: \n",
    "               # selected_df = select_quotes_chunk(chunk, vocabulary)\n",
    "    return selected_df\n",
    "\n",
    "\n",
    "import random, string\n",
    "\n",
    "def randomword(length):\n",
    "    letters = string.ascii_lowercase\n",
    "    return ''.join(random.choice(letters) for i in range(length))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6485950-baf8-4991-8f23-352efaddb36b",
   "metadata": {},
   "source": [
    "### Constants "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27db09ff-680c-4ffd-b303-c36b6c012026",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = 'data/' # ../ doesn't work for me for some reason\n",
    "QUOTEBANK_2020 = DATA_FOLDER+ \"quotes-2020.json.bz2\"\n",
    "QUOTEBANK_2019 = DATA_FOLDER+ \"quotes-2019.json.bz2\"\n",
    "QUOTEBANK_2017 = DATA_FOLDER+ \"quotes-2017.json.bz2\"\n",
    "QUOTEBANK_2015 = DATA_FOLDER+ \"quotes-2015.json.bz2\"\n",
    "QUOTEBANK_2018 = DATA_FOLDER+ \"quotes-2018.json.bz2\"\n",
    "QUOTEBANK_2016 = DATA_FOLDER+ \"quotes-2016.json.bz2\"\n",
    "\n",
    "KEYWORDS_LIST = ('women\\'s right','Equal opportunities','Equal rights','Equal status','equal pay',\n",
    "              'gender gap','Gender discrimination','Gender equality','Sexual harrassment',\n",
    "              'Women empowerment','women victim','women immigration','Women emancipation',\n",
    "              'women\\'s participation','Western women','non-western woman','Muslim women',\n",
    "              'Equal wages','Gender equality','gender equity','Men and women','women and men',\n",
    "              'women oppression','niqab ban','struggle of girls','struggle of women','war against women',\n",
    "              'oppression of girls','oppression of women','women oppression','women\\'s opression','liberate women',\n",
    "              'religious oppresion','abuse of women','Male oppression','Female oppression','Exploitation of women',\n",
    "              'Indigenous women','Patriarchal culture','gender equality','child care','men pay','percentage men',\n",
    "              'pay percentage','sexual harassment','women girls','girls women',\n",
    "              'rates women','women according','female mayors','share women','women movement',\n",
    "              'see women','gender stereotypes','gender gap',\n",
    "              'women representation','sex discrimination','states women','lose weight',\n",
    "              'women rights','woman time',\n",
    "              'based gender',\n",
    "              'proportional electoral','female candidates','gender-based violence','entirely female','cities female')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18335ed-86e8-4b6a-8088-8c6806ffa113",
   "metadata": {},
   "source": [
    "### Select and pickle of quotes of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fbcb35-0447-4748-abc8-6b0877a96da9",
   "metadata": {},
   "source": [
    "Note: This code has to be run once to create the pickle files containing the quotes of interest. For futher use, the dataframe is direcly loaded from the pickle files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73091be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk with 10000 rows\n",
      "Processing chunk with 10000 rows\n",
      "Processing chunk with 10000 rows\n",
      "Processing chunk with 10000 rows\n",
      "Processing chunk with 10000 rows\n",
      "Processing chunk with 10000 rows\n",
      "Processing chunk with 10000 rows\n",
      "Processing chunk with 10000 rows\n",
      "Processing chunk with 10000 rows\n",
      "Processing chunk with 10000 rows\n",
      "Processing chunk with 10000 rows\n",
      "Processing chunk with 10000 rows\n",
      "Processing chunk with 10000 rows\n",
      "Processing chunk with 10000 rows\n",
      "Processing chunk with 10000 rows\n",
      "Processing chunk with 10000 rows\n",
      "Processing chunk with 10000 rows\n",
      "Processing chunk with 10000 rows\n",
      "Processing chunk with 10000 rows\n",
      "Processing chunk with 10000 rows\n",
      "Processing chunk with 7527 rows\n",
      "Wall time: 17.1 s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%time QOI_TEST_DF_Dumped = select_and_dump(DATA_FOLDER+ \"quotes-2019-nytimes.json.bz2\", KEYWORDS_LIST, 10 ** 4, year = 'qb_TEST') \n",
    "QOI_TEST_DF_Dumped.to_pickle('files/'+'TEST_selected.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f328a9d1-0af5-4346-b2cd-d9c08247f6ae",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17828/290846849.py\u001b[0m in \u001b[0;36mselect_and_dump\u001b[1;34m(path_to_file, vocabulary, chunksize, year)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mselect_and_dump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_to_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myear\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'replace_me'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_to_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'bz2'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mdf_reader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_reader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m             \u001b[1;31m#Dump selected quotes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m             \u001b[0mselected_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselect_quotes_chunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\ada\\lib\\site-packages\\pandas\\io\\json\\_json.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    793\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    794\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 795\u001b[1;33m         \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mislice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    796\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m             \u001b[0mlines_json\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_combine_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\ada\\lib\\bz2.py\u001b[0m in \u001b[0;36mread1\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    193\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0msize\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m                 \u001b[0msize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDEFAULT_BUFFER_SIZE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 195\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mreadinto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\ada\\lib\\_compression.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mreadinto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mview\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mview\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"B\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mbyte_view\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbyte_view\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m             \u001b[0mbyte_view\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\ada\\lib\\_compression.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    101\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m                     \u001b[0mrawblock\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mb\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_decompressor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecompress\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrawblock\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'QOI_2020_DF_Dumped' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17828/3102238988.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#The two first have been directly dumped into multiples pickle files\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'time'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"QOI_2020_DF_Dumped = select_and_dump(QUOTEBANK_2020, KEYWORDS_LIST, 10 ** 6, year = 'qb_2020')\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mQOI_2020_DF_Dumped\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'files/'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'2020_selected.pkl'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'QOI_2020_DF_Dumped' is not defined"
     ]
    }
   ],
   "source": [
    "#The two first have been directly dumped into multiples pickle files\n",
    "#%time QOI_2020_DF_Dumped = select_and_dump(QUOTEBANK_2020, KEYWORDS_LIST, 10 ** 6, year = 'qb_2020') \n",
    "#QOI_2020_DF_Dumped.to_pickle('files/'+'2020_selected.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e288f0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%time QOI_2019_DF_Dumped = select_and_dump(QUOTEBANK_2019, KEYWORDS_LIST, 10 ** 6, year = 'qb_2019')\n",
    "#QOI_2019_DF_Dumped.to_pickle('files/'+'2019_selected.pkl')\n",
    "\n",
    "#%time QOI_2018_DF = select_quotes_one_year(QUOTEBANK_2018,KEYWORDS_LIST,10 ** 6, year = 'qb_2018')\n",
    "#QOI_2018_DF.to_pickle('files/'+'2018_selected.pkl')\n",
    "\n",
    "#%time QOI_2017_DF = select_quotes_one_year(QUOTEBANK_2017,KEYWORDS_LIST,10 ** 6, year = 'qb_2017')\n",
    "#QOI_2017_DF.to_pickle('files/'+'2017_selected.pkl')\n",
    "\n",
    "#%time QOI_2016_DF = select_quotes_one_year(QUOTEBANK_2016,KEYWORDS_LIST,10 ** 6, year = 'qb_2016')\n",
    "#QOI_2016_DF.to_pickle('files/'+'2016_selected.pkl')\n",
    "\n",
    "#%time QOI_2015_DF = select_quotes_one_year(QUOTEBANK_2015,KEYWORDS_LIST,10 ** 6, year = 'qb_2015')\n",
    "#QOI_2015_DF.to_pickle('files/'+'2015_selected.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37178ef-3230-4ebf-9f66-5e88bf2ff4c0",
   "metadata": {},
   "source": [
    "### Load dataframe of selected quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a75e117f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'files/TEST_selected.pkl'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'files/'+ files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3d2474a4-0ab1-46e3-8aa5-8c6445b5e59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the dataframes obtained from each of the pickle file. \n",
    "# files = ('2015_selected.pkl','2016_selected.pkl','2017_selected.pkl','2018_selected.pkl','2019_selected.pkl','2020_selected.pkl')\n",
    "# df = pd.concat([pd.read_pickle('files/'+ fp) for fp in files], ignore_index=True)\n",
    "df = pd.read_pickle('files/TEST_selected.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "14ea9e5f-fcf3-4d6a-b111-fe2cff46806b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quoteID</th>\n",
       "      <th>quotation</th>\n",
       "      <th>speaker</th>\n",
       "      <th>qids</th>\n",
       "      <th>date</th>\n",
       "      <th>numOccurrences</th>\n",
       "      <th>probas</th>\n",
       "      <th>urls</th>\n",
       "      <th>phase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200262</th>\n",
       "      <td>2019-07-02-019858</td>\n",
       "      <td>He has spoken up for women's issues and women'...</td>\n",
       "      <td>Serena Williams</td>\n",
       "      <td>[Q11459]</td>\n",
       "      <td>2019-07-02 23:04:15</td>\n",
       "      <td>1</td>\n",
       "      <td>[[Serena Williams, 0.8938], [None, 0.0997], [A...</td>\n",
       "      <td>[https://www.nytimes.com/2019/07/02/sports/ser...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201055</th>\n",
       "      <td>2019-03-13-126346</td>\n",
       "      <td>With this cruel sentence, the Iranian authorit...</td>\n",
       "      <td>Kumi Naidoo</td>\n",
       "      <td>[Q1363729]</td>\n",
       "      <td>2019-03-13 16:55:11</td>\n",
       "      <td>4</td>\n",
       "      <td>[[Kumi Naidoo, 0.93], [None, 0.0561], [Nasrin ...</td>\n",
       "      <td>[https://www.seattletimes.com/opinion/two-wome...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201211</th>\n",
       "      <td>2019-05-02-052509</td>\n",
       "      <td>It basically said we needed to address sexual ...</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>2019-05-02 20:27:34</td>\n",
       "      <td>1</td>\n",
       "      <td>[[None, 0.5979], [Marcia McNutt, 0.4021]]</td>\n",
       "      <td>[http://www.nytimes.com/2019/05/02/science/nat...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203171</th>\n",
       "      <td>2019-08-29-121813</td>\n",
       "      <td>You had several female candidates who were all...</td>\n",
       "      <td>Randi Weingarten</td>\n",
       "      <td>[Q7291716]</td>\n",
       "      <td>2019-08-29 19:47:38</td>\n",
       "      <td>1</td>\n",
       "      <td>[[Randi Weingarten, 0.7464], [None, 0.1963], [...</td>\n",
       "      <td>[http://mobile.nytimes.com/2019/08/29/us/polit...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203360</th>\n",
       "      <td>2019-03-25-105644</td>\n",
       "      <td>We're doing all these grown-up things like mak...</td>\n",
       "      <td>Bill Keller</td>\n",
       "      <td>[Q3640044, Q4909680, Q862237]</td>\n",
       "      <td>2019-03-25 21:30:55</td>\n",
       "      <td>1</td>\n",
       "      <td>[[Bill Keller, 0.8768], [None, 0.1232]]</td>\n",
       "      <td>[http://www.nytimes.com/2019/03/25/business/ch...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  quoteID                                          quotation  \\\n",
       "200262  2019-07-02-019858  He has spoken up for women's issues and women'...   \n",
       "201055  2019-03-13-126346  With this cruel sentence, the Iranian authorit...   \n",
       "201211  2019-05-02-052509  It basically said we needed to address sexual ...   \n",
       "203171  2019-08-29-121813  You had several female candidates who were all...   \n",
       "203360  2019-03-25-105644  We're doing all these grown-up things like mak...   \n",
       "\n",
       "                 speaker                           qids                date  \\\n",
       "200262   Serena Williams                       [Q11459] 2019-07-02 23:04:15   \n",
       "201055       Kumi Naidoo                     [Q1363729] 2019-03-13 16:55:11   \n",
       "201211              None                             [] 2019-05-02 20:27:34   \n",
       "203171  Randi Weingarten                     [Q7291716] 2019-08-29 19:47:38   \n",
       "203360       Bill Keller  [Q3640044, Q4909680, Q862237] 2019-03-25 21:30:55   \n",
       "\n",
       "        numOccurrences                                             probas  \\\n",
       "200262               1  [[Serena Williams, 0.8938], [None, 0.0997], [A...   \n",
       "201055               4  [[Kumi Naidoo, 0.93], [None, 0.0561], [Nasrin ...   \n",
       "201211               1          [[None, 0.5979], [Marcia McNutt, 0.4021]]   \n",
       "203171               1  [[Randi Weingarten, 0.7464], [None, 0.1963], [...   \n",
       "203360               1            [[Bill Keller, 0.8768], [None, 0.1232]]   \n",
       "\n",
       "                                                     urls phase  \n",
       "200262  [https://www.nytimes.com/2019/07/02/sports/ser...     E  \n",
       "201055  [https://www.seattletimes.com/opinion/two-wome...     E  \n",
       "201211  [http://www.nytimes.com/2019/05/02/science/nat...     E  \n",
       "203171  [http://mobile.nytimes.com/2019/08/29/us/polit...     E  \n",
       "203360  [http://www.nytimes.com/2019/03/25/business/ch...     E  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0bcc2c3b-9b79-4519-b6aa-7f3d9aa4a476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataframe has 8 entries\n"
     ]
    }
   ],
   "source": [
    "print(f'The dataframe has {len(df)} entries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eab691c9-49dd-4ec3-a9ca-8b428c448731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200262                 He has spoken up for women's issues and women's rights, especially in tennis, forever.\n",
       "201055    With this cruel sentence, the Iranian authorities appear to be seeking to make an example of Nas...\n",
       "201211    It basically said we needed to address sexual harassment as seriously as other forms of academic...\n",
       "203171                   You had several female candidates who were all bringing their own brand of feminism.\n",
       "203360    We're doing all these grown-up things like making sure that we have policies on paid leave and s...\n",
       "Name: quotation, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_colwidth = 100\n",
    "df.head()['quotation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4554f1f0-d9d9-442e-a06e-a0c511a0d504",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3b8cf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31648f2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9412167",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec19f137",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6938f0bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88220bb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7198c819",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1344d6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
